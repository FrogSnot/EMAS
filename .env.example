# EMAS Configuration
# ---------------------------------------------------------------
# Copy this file to `.env` and fill in the values.

# Required: Your LLM API key.
# Supports OpenAI, Google Gemini, or any OpenAI-compatible provider.
EMAS_API_KEY=sk-...

# Optional: Force a specific provider ("openai" or "google").
# Auto-detected from env vars / URL if omitted.
# EMAS_PROVIDER=openai

# Optional: API base URL (defaults per provider).
# OpenAI:  https://api.openai.com/v1
# Ollama:  http://localhost:11434/v1
# Google:  https://generativelanguage.googleapis.com/v1beta
# EMAS_API_BASE_URL=https://api.openai.com/v1

# Optional: Model name (defaults: gpt-4o-mini for OpenAI, gemini-2.0-flash-lite for Google).
# EMAS_MODEL=gpt-4o-mini

# Provider-specific env vars (also supported)
# ---------------------------------------------------------------

# OpenAI
# OPENAI_API_KEY=sk-...
# OPENAI_API_BASE=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o-mini

# Google Gemini
# GOOGLE_API_KEY=AIza...
# GOOGLE_MODEL=gemini-2.0-flash-lite

# Judge (Orchestrator) overrides
# ---------------------------------------------------------------
# Use a separate, smarter model to evaluate team outputs.
# All of these fall back to the agent config if omitted.
# EMAS_JUDGE_MODEL=gpt-4o
# EMAS_JUDGE_API_KEY=sk-...
# EMAS_JUDGE_API_BASE_URL=https://api.openai.com/v1

# Logging level (trace, debug, info, warn, error).
# RUST_LOG=info
